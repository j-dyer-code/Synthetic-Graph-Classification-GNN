{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f47936b-413e-4a87-a426-8f2c0adcfdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IMPORTS\n",
    "\"\"\"\n",
    "\n",
    "# Core Python libraries\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from IPython.display import display\n",
    "\n",
    "# Data handling and numerical operations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import igraph as ig\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Machine Learning and Evaluation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve,\n",
    "    precision_recall_curve, average_precision_score, accuracy_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import umap\n",
    "import optuna\n",
    "\n",
    "# PyTorch and PyTorch Geometric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import (\n",
    "    GATConv, GATv2Conv, GCNConv, SAGEConv, GINConv, TransformerConv,\n",
    "    global_mean_pool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e88a0f-3997-48da-9a1a-937ddbf670f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CONFIGURATION\n",
    "\"\"\"\n",
    "# --- General Settings ---\n",
    "DEBUG_MODE = False\n",
    "SEED = 42\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "\n",
    "# --- Data Generation ---\n",
    "BATCH_SIZE_GEN = 10 if DEBUG_MODE else 20\n",
    "TOTAL_GRAPHS_PER_FAMILY = 100 if DEBUG_MODE else 400\n",
    "FAMILIES = [\"erdos_renyi\", \"barabasi_albert\", \"watts_strogatz\", \"stochastic_block_model\", \"holme_kim\"]\n",
    "FAMILY_NAMES_PRETTY = [\"ER\", \"BA\", \"WS\", \"SBM\", \"HK\"]\n",
    "\n",
    "# --- Model Architectures ---\n",
    "MODELS = ['GAT', 'GCN', 'SAGE', 'GIN', 'GATV2', 'GTN']\n",
    "\n",
    "# --- Training and Tuning ---\n",
    "TRAIN_RATIO = 0.8\n",
    "BATCH_SIZE_TRAIN = 32\n",
    "NUM_TRIALS_OPTUNA = 5 if DEBUG_MODE else 50\n",
    "MAX_EPOCHS_TRAIN = 10 if DEBUG_MODE else 100\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "MIN_NODES = 500 if DEBUG_MODE else 5_000\n",
    "MAX_NODES = 1000 if DEBUG_MODE else 10_000\n",
    "\n",
    "\n",
    "# --- Directories ---\n",
    "PLOT_DIR = \"evaluation_plots\"\n",
    "FEATURE_DIR = \"graph_features\"\n",
    "GRAPH_DIR = \"graph_objects\"\n",
    "FINAL_MODELS_DIR = \"final_models\"\n",
    "METRICS_DIR = 'metrics'\n",
    "DATA_PKL_PATH = 'pyg_data.pkl'\n",
    "METRICS_PKL_PATH = os.path.join(METRICS_DIR, 'metrics_dict.pkl')\n",
    "\n",
    "# --- Visualization ---\n",
    "CLASS_COLORS = {\n",
    "    \"ER\": \"#66c2a5\",\n",
    "    \"BA\": \"#fc8d62\",\n",
    "    \"WS\": \"#8da0cb\",\n",
    "    \"SBM\": \"#e78ac3\",\n",
    "    \"HK\": \"#a6d854\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7aee08-c44b-494d-ae15-22743ee41c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "UTILITY FUNCTIONS\n",
    "\"\"\"\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Set up directories and random seeds for reproducibility.\"\"\"\n",
    "    os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "    os.makedirs(FEATURE_DIR, exist_ok=True)\n",
    "    os.makedirs(GRAPH_DIR, exist_ok=True)\n",
    "    os.makedirs(FINAL_MODELS_DIR, exist_ok=True)\n",
    "    os.makedirs(METRICS_DIR, exist_ok=True)\n",
    "\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "        # Configuration to prevent fragmentation issues on some systems\n",
    "        os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6209c6ee-b577-4d9e-a918-5ba7ca98ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA GENERATION & FEATURE EXTRACTION\n",
    "\"\"\"\n",
    "\n",
    "def compute_lightweight_features_igraph(G):\n",
    "    \"\"\"\n",
    "    Computes lightweight node-level and graph-level features for an igraph graph.\n",
    "    This version includes checks to prevent NaN or Inf values in graph features.\n",
    "    \"\"\"\n",
    "    node_features_list = []\n",
    "    if G.vcount() > 0:\n",
    "        node_degrees = G.degree()\n",
    "        node_pagerank = G.pagerank()\n",
    "        node_coreness = G.coreness()\n",
    "        node_eigenvector_centrality = G.eigenvector_centrality()\n",
    "        node_closeness_centrality = G.closeness()\n",
    "\n",
    "        for i in range(G.vcount()):\n",
    "            node_features = {\n",
    "                'Degree': node_degrees[i],\n",
    "                'Pagerank': node_pagerank[i],\n",
    "                'K-Core': node_coreness[i],\n",
    "                'Eigenvector': node_eigenvector_centrality[i],\n",
    "                'Closeness': node_closeness_centrality[i] if node_closeness_centrality[i] is not None else 0.0,\n",
    "            }\n",
    "            node_features_list.append(node_features)\n",
    "\n",
    "    # --- Graph-level features ---\n",
    "    degrees = G.degree()\n",
    "\n",
    "    # Calculate potentially problematic features first\n",
    "    assortativity = G.assortativity_degree(directed=False) if G.vcount() > 1 else 0.0\n",
    "    clustering = G.transitivity_undirected() if G.vcount() > 1 else 0.0\n",
    "    avg_path_len = G.average_path_length() if G.vcount() > 1 else 0.0\n",
    "\n",
    "    graph_features_dict = {\n",
    "        \"Degree Variance\": np.var(degrees) if degrees else 0.0,\n",
    "        # IMPORTANT: Check for NaN/Inf and replace with 0.0\n",
    "        \"Assortativity\": assortativity if np.isfinite(assortativity) else 0.0,\n",
    "        \"Density\": G.density(),\n",
    "        \"Clustering\": clustering if np.isfinite(clustering) else 0.0,\n",
    "        \"Average Path Length\": avg_path_len if np.isfinite(avg_path_len) else 0.0,\n",
    "        \"edges\": G.ecount(),\n",
    "        \"nodes\": G.vcount()\n",
    "    }\n",
    "    return node_features_list, graph_features_dict\n",
    "\n",
    "def generate_single_graph(family, num_nodes):\n",
    "    \"\"\"\n",
    "    Generates a single random graph from a specified family. \n",
    "\n",
    "    Args:\n",
    "        family (str): The name of the graph family.\n",
    "        num_nodes (int): The number of nodes in the graph.\n",
    "\n",
    "    Returns:\n",
    "        ig.Graph or None: The generated igraph object, or None if generation fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if family == \"erdos_renyi\":\n",
    "            p = random.uniform(0.001, 0.0015)\n",
    "            G = ig.Graph.Erdos_Renyi(n=num_nodes, p=p) # \n",
    "        elif family == \"barabasi_albert\":\n",
    "            m = random.randint(3, 5)\n",
    "            G = ig.Graph.Barabasi(n=num_nodes, m=m) # \n",
    "        elif family == \"watts_strogatz\":\n",
    "            k = random.randint(4, 6) # \n",
    "            p = random.uniform(0.3, 0.6) # \n",
    "            G = ig.Graph.Watts_Strogatz(dim=1, size=num_nodes, nei=k, p=p) # \n",
    "        elif family == \"stochastic_block_model\":\n",
    "            num_blocks = random.randint(4, 6)\n",
    "            block_sizes = [num_nodes // num_blocks] * num_blocks # \n",
    "            for i in range(num_nodes % num_blocks):\n",
    "                block_sizes[i] += 1\n",
    "            p_within = np.random.uniform(0.001, 0.005)\n",
    "            p_between = np.random.uniform(0.0005, 0.002, size=(num_blocks, num_blocks))\n",
    "            p_matrix = (p_between + p_between.T) / 2\n",
    "            np.fill_diagonal(p_matrix, p_within)\n",
    "            G = ig.Graph.SBM(num_nodes, p_matrix.tolist(), block_sizes=block_sizes) # \n",
    "        elif family == \"holme_kim\":\n",
    "            import networkx as nx\n",
    "            m = random.randint(3, 5) # \n",
    "            p = random.uniform(0.2, 0.3) # \n",
    "            G_nx = nx.powerlaw_cluster_graph(num_nodes, m, p) # \n",
    "            if not nx.is_connected(G_nx):\n",
    "                largest_cc = max(nx.connected_components(G_nx), key=len)\n",
    "                G_nx = G_nx.subgraph(largest_cc).copy()\n",
    "            G = ig.Graph.from_networkx(G_nx) # \n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        if not G.is_connected():\n",
    "            G = G.components().giant()\n",
    "        return G\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Graph generation failed for {family} with {num_nodes} nodes. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def run_batched_generation():\n",
    "    \"\"\"\n",
    "    Generates and saves graphs and their features in batches. \n",
    "\n",
    "    For each graph family, it generates a total of `TOTAL_GRAPHS_PER_FAMILY` graphs,\n",
    "    saving them in smaller batches to manage memory.\n",
    "    \"\"\"\n",
    "    print(\"Starting batched graph generation...\")\n",
    "    global_id = 0\n",
    "    for family in FAMILIES: # \n",
    "        family_idx = FAMILIES.index(family)\n",
    "        graphs_generated = 0\n",
    "        batch_id = 0\n",
    "        while graphs_generated < TOTAL_GRAPHS_PER_FAMILY:\n",
    "            batch_graphs = [] # \n",
    "            batch_node_features = [] # \n",
    "            batch_graph_features = [] # \n",
    "\n",
    "            for _ in range(BATCH_SIZE_GEN):\n",
    "                if graphs_generated >= TOTAL_GRAPHS_PER_FAMILY:\n",
    "                    break # \n",
    "\n",
    "                num_nodes = random.randint(MIN_NODES, MAX_NODES)\n",
    "                G = generate_single_graph(family, num_nodes)\n",
    "                if G is None:\n",
    "                    continue\n",
    "\n",
    "                node_features, graph_features = compute_lightweight_features_igraph(G) # \n",
    "                graph_features[\"family\"] = family_idx\n",
    "                graph_features[\"graph_id\"] = global_id\n",
    "\n",
    "                batch_graphs.append(G) # \n",
    "                batch_node_features.append(node_features) # \n",
    "                batch_graph_features.append(graph_features) # \n",
    "\n",
    "                graphs_generated += 1\n",
    "                global_id += 1\n",
    "\n",
    "            if not batch_graphs:\n",
    "                batch_id += 1 # \n",
    "                continue\n",
    "\n",
    "            # Save batch data\n",
    "            feature_df = pd.DataFrame(batch_graph_features)\n",
    "            feature_df.to_csv(os.path.join(FEATURE_DIR, f\"{family}_graph_features_batch_{batch_id:02d}.csv\"), index=False)\n",
    "            with open(os.path.join(FEATURE_DIR, f\"{family}_node_features_batch_{batch_id:02d}.pkl\"), \"wb\") as f: # \n",
    "                pickle.dump(batch_node_features, f) # \n",
    "            with open(os.path.join(GRAPH_DIR, f\"{family}_graphs_batch_{batch_id:02d}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(batch_graphs, f)\n",
    "\n",
    "            print(f\"Saved batch {batch_id:02d} for {family} ({len(batch_graphs)} graphs)\")\n",
    "            batch_id += 1 # \n",
    "            gc.collect()\n",
    "    print(\"Graph generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941c08f-fb6b-40f5-a526-4ed0d6a39581",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FEATURE ENGINEERING AND SELECTION\n",
    "\"\"\"\n",
    "\n",
    "def get_important_features(features_list_of_dicts, labels):\n",
    "    \"\"\"\n",
    "    Identifies important features using a Random Forest Classifier. \n",
    "\n",
    "    It runs the classifier multiple times to get a stable estimate of feature\n",
    "    importance and retains features that contribute to a cumulative importance\n",
    "    of at least 80%.\n",
    "\n",
    "    Args:\n",
    "        features_list_of_dicts (list): A list of feature dictionaries. \n",
    "        labels (list): A list of corresponding labels. \n",
    "\n",
    "    Returns:\n",
    "        list: A list of names of the important features.\n",
    "    \"\"\"\n",
    "    if not features_list_of_dicts:\n",
    "        return []\n",
    "    feature_names = list(features_list_of_dicts[0].keys())\n",
    "    if not feature_names:\n",
    "        return []\n",
    "\n",
    "    all_feature_values = [[graph_features[name] for name in feature_names] for graph_features in features_list_of_dicts] # \n",
    "    \n",
    "    # Use multiple runs to stabilize importance scores\n",
    "    n_runs = 5\n",
    "    importances = np.zeros((n_runs, len(feature_names)))\n",
    "    for i in range(n_runs):\n",
    "        rf = RandomForestClassifier(random_state=i)\n",
    "        rf.fit(all_feature_values, labels)\n",
    "        importances[i, :] = rf.feature_importances_ # \n",
    "\n",
    "    mean_importances = np.mean(importances, axis=0)\n",
    "    \n",
    "    feature_df = pd.DataFrame({'Feature': feature_names, 'Importance': mean_importances})\n",
    "    sorted_feature_df = feature_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "    sorted_feature_df['Cumulative Importance'] = sorted_feature_df['Importance'].cumsum()\n",
    "    \n",
    "    print(\"Feature Importance Report:\")\n",
    "    display(sorted_feature_df)\n",
    "\n",
    "    # Retain features explaining at least 80% of importance\n",
    "    threshold = 0.8 # \n",
    "    important_df = sorted_feature_df[sorted_feature_df['Cumulative Importance'] >= threshold]\n",
    "    \n",
    "    if not important_df.empty:\n",
    "        cutoff_index = important_df.index[0]\n",
    "        important_feature_names = sorted_feature_df.iloc[:cutoff_index + 1]['Feature'].tolist()\n",
    "    else:\n",
    "        important_feature_names = sorted_feature_df['Feature'].tolist() # \n",
    "\n",
    "    return important_feature_names\n",
    "\n",
    "\n",
    "def get_pruned_features(features_list_of_dicts, important_feature_names):\n",
    "    \"\"\"\n",
    "    Filters a list of feature dictionaries to keep only important features.\n",
    "\n",
    "    Args:\n",
    "        features_list_of_dicts (list): The original list of feature dictionaries.\n",
    "        important_feature_names (list): A list of feature names to keep. \n",
    "\n",
    "    Returns:\n",
    "        list: A new list of dictionaries containing only the important features.\n",
    "    \"\"\"\n",
    "    if not features_list_of_dicts:\n",
    "        return [] # \n",
    "    \n",
    "    unimportant_features = set(features_list_of_dicts[0].keys()) - set(important_feature_names)\n",
    "    print(f\"Pruning features: {list(unimportant_features)}\")\n",
    "\n",
    "    pruned_features = [] # \n",
    "    for graph_features in features_list_of_dicts:\n",
    "        pruned_graph = {name: graph_features[name] for name in important_feature_names if name in graph_features}\n",
    "        pruned_features.append(pruned_graph) # \n",
    "    \n",
    "    return pruned_features\n",
    "\n",
    "\n",
    "def prune_features(features_list_of_dicts, labels, level):\n",
    "    \"\"\"\n",
    "    Iteratively prunes features until the set of important features stabilizes. \n",
    "\n",
    "    Args:\n",
    "        features_list_of_dicts (list): A list of feature dictionaries.\n",
    "        labels (list): A list of corresponding labels. \n",
    "        level (str): The feature level ('node' or 'graph') for titling plots.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - list: The final list of pruned feature dictionaries.\n",
    "            - int: The number of retained features.\n",
    "    \"\"\"\n",
    "    if not features_list_of_dicts:\n",
    "        return [], 0\n",
    "    \n",
    "    current_features = features_list_of_dicts # \n",
    "    \n",
    "    while True:\n",
    "        num_before_pruning = len(current_features[0])\n",
    "        important_names = get_important_features(current_features, labels)\n",
    "        current_features = get_pruned_features(current_features, important_names)\n",
    "        num_after_pruning = len(current_features[0])\n",
    "        \n",
    "        print(f\"Pruning Pass ({level}): {num_before_pruning} -> {num_after_pruning} features.\")\n",
    "        if num_after_pruning == num_before_pruning:\n",
    "            #  No more features were removed, stabilization reached.\n",
    "            break # \n",
    "\n",
    "    if current_features:\n",
    "        visualise_features(current_features, labels, level)\n",
    "        return current_features, len(current_features[0])\n",
    "    \n",
    "    print(f\"All {level} features were pruned.\")\n",
    "    return [], 0\n",
    "\n",
    "\n",
    "def visualise_features(features, labels, level):\n",
    "    \"\"\"\n",
    "    Generates and saves plots to visualize feature distributions and correlations.\n",
    "\n",
    "    Args:\n",
    "        features (list): A list of feature dictionaries.\n",
    "        labels (list): Corresponding integer-coded labels.\n",
    "        level (str): A string indicating the feature level ('node' or 'graph').\n",
    "    \"\"\"\n",
    "    if not features:\n",
    "        print(\"No features to visualize.\")\n",
    "        return\n",
    "\n",
    "    feature_names = list(features[0].keys())\n",
    "\n",
    "    # Restructure data for seaborn plots\n",
    "    df_list = []\n",
    "    for i, feature_dict in enumerate(features):\n",
    "        family = FAMILY_NAMES_PRETTY[labels[i]]\n",
    "        for feature_name, value in feature_dict.items():\n",
    "            df_list.append({'Value': value, 'Feature': feature_name, 'Family': family})\n",
    "    df = pd.DataFrame(df_list)\n",
    "    df.to_csv('global_features_df.csv')\n",
    "\n",
    "    # --- Distribution and Box Plots using FacetGrid ---\n",
    "    # Get unique features\n",
    "    unique_features = df['Feature'].unique()\n",
    "    num_features = len(unique_features)\n",
    "    num_cols = min(4, num_features)\n",
    "\n",
    "    g = sns.FacetGrid(data=df, col='Feature', hue='Family', palette=\"Set2\", col_wrap=num_features, height=4, aspect=1.2, sharey=False, sharex=False, legend_out=True)\n",
    "\n",
    "    # Map KDE plots to the upper row\n",
    "    g.map(sns.kdeplot, 'Value', fill=True, alpha=0.5)\n",
    "    handles, labels = g.axes[0].get_legend_handles_labels()\n",
    "    \n",
    "    g.figure.legend(\n",
    "        handles, labels,\n",
    "        loc='upper center',\n",
    "        bbox_to_anchor=(0.5, 1.2),  # Adjust vertical position\n",
    "        ncol=len(FAMILIES),\n",
    "        title='Family',\n",
    "        frameon=False\n",
    "    )    \n",
    "    plt.savefig(os.path.join(PLOT_DIR, f\"{level}_kde.pdf\"), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # Create a second FacetGrid for boxplots\n",
    "    g_box = sns.FacetGrid(data=df, col='Feature', hue='Family', palette=\"Set2\", col_wrap=num_features, height=4, aspect=1.2, sharey=False, sharex=False)\n",
    "\n",
    "    g_box.map(sns.boxplot, 'Family', 'Value')\n",
    "\n",
    "    plt.savefig(os.path.join(PLOT_DIR, f\"{level}_box.pdf\"), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # --- Correlation Heatmap ---\n",
    "\n",
    "    df_pivot = df.pivot_table(index=df.index // len(feature_names), columns='Feature', values='Value')\n",
    "\n",
    "    corr = df_pivot.corr(numeric_only=True)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", square=True, annot_kws={\"size\": 26})\n",
    "    plt.title(f\"{level.capitalize()} Feature Correlation Heatmap\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOT_DIR, f\"{level}_feature_correlation.pdf\"), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def convert_to_pyg(graphs, all_node_features, important_node_feature_names, pruned_graph_features, labels):\n",
    "    \"\"\"\n",
    "    Converts igraph graphs and features into PyTorch Geometric Data objects. \n",
    "\n",
    "    This function performs a direct and efficient conversion from igraph,\n",
    "    bypassing slower intermediate formats like NetworkX. \n",
    "\n",
    "    Args:\n",
    "        graphs (list): A list of igraph graph objects. \n",
    "        all_node_features (list): A list of lists of node feature dictionaries. \n",
    "        important_node_feature_names (list): A list of node feature names to retain. \n",
    "        pruned_graph_features (list): A list of pruned graph-level feature dictionaries. \n",
    "        labels (list): A list of graph family labels. \n",
    "\n",
    "    Returns:\n",
    "        list: A list of PyG `Data` objects. \n",
    "    \"\"\"\n",
    "    pyg_data = [] # \n",
    "    for i, G_ig in enumerate(graphs):\n",
    "        try:\n",
    "            # Convert edge list to PyG edge_index format\n",
    "            edge_list = G_ig.get_edgelist()\n",
    "            edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous() # \n",
    "\n",
    "            # Process node features\n",
    "            node_feature_tensors = []\n",
    "            if all_node_features[i] and important_node_feature_names:\n",
    "                for node_feat_dict in all_node_features[i]:\n",
    "                    #  Ensure consistent feature order and handle missing values\n",
    "                    node_feat = [node_feat_dict.get(name, 0.0) for name in important_node_feature_names] # \n",
    "                    node_feature_tensors.append(node_feat)\n",
    "            \n",
    "            if node_feature_tensors:\n",
    "                data_x = torch.tensor(node_feature_tensors, dtype=torch.float) # \n",
    "            else:\n",
    "                #  Create an empty tensor with the correct feature dimension for graphs with no nodes\n",
    "                data_x = torch.empty((G_ig.vcount(), len(important_node_feature_names)), dtype=torch.float) # \n",
    "\n",
    "            # Process graph features\n",
    "            if pruned_graph_features and pruned_graph_features[i]:\n",
    "                #  Ensure consistent feature order\n",
    "                graph_feat_values = list(pruned_graph_features[i].values())\n",
    "                data_graph_features = torch.tensor(graph_feat_values, dtype=torch.float) # \n",
    "            else:\n",
    "                data_graph_features = torch.empty((0,), dtype=torch.float)\n",
    "\n",
    "            # Create PyG Data object\n",
    "            data = Data(\n",
    "                x=data_x, # \n",
    "                edge_index=edge_index, # \n",
    "                y=torch.tensor(labels[i], dtype=torch.long), # \n",
    "                graph_features=data_graph_features, # \n",
    "                num_nodes=G_ig.vcount() # \n",
    "            )\n",
    "            pyg_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting graph {i} to PyG: {e}\") # \n",
    "            continue # \n",
    "            \n",
    "    random.shuffle(pyg_data)\n",
    "    return pyg_data\n",
    "\n",
    "\n",
    "def load_and_preprocess_dataset():\n",
    "    \"\"\"\n",
    "    Loads generated data, prunes features, and converts to PyG format. \n",
    "\n",
    "    This function orchestrates the entire preprocessing pipeline.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - list: The final list of PyG `Data` objects.\n",
    "            - int: The number of retained node features.\n",
    "            - int: The number of retained graph features.\n",
    "    \"\"\"\n",
    "    print(\"Loading and preprocessing dataset...\")\n",
    "    # --- 1. Load all batched data from disk ---\n",
    "    all_graphs, all_node_features, all_graph_features, all_labels = [], [], [], [] # \n",
    "    for family in FAMILIES:\n",
    "        batch_id = 0\n",
    "        while True:\n",
    "            graph_feature_file = os.path.join(FEATURE_DIR, f\"{family}_graph_features_batch_{batch_id:02d}.csv\")\n",
    "            node_feature_file = os.path.join(FEATURE_DIR, f\"{family}_node_features_batch_{batch_id:02d}.pkl\")\n",
    "            graph_file = os.path.join(GRAPH_DIR, f\"{family}_graphs_batch_{batch_id:02d}.pkl\")\n",
    "\n",
    "            if not all(os.path.exists(f) for f in [graph_feature_file, node_feature_file, graph_file]): # \n",
    "                break\n",
    "\n",
    "            graph_feature_df = pd.read_csv(graph_feature_file)\n",
    "            all_graph_features.extend(graph_feature_df.drop(['family', 'graph_id', 'nodes','edges'], axis=1).to_dict('records')) # \n",
    "            all_labels.extend(graph_feature_df['family'].tolist()) # \n",
    "            with open(node_feature_file, \"rb\") as f: # \n",
    "                all_node_features.extend(pickle.load(f)) # \n",
    "            with open(graph_file, \"rb\") as f:\n",
    "                all_graphs.extend(pickle.load(f)) # \n",
    "            batch_id += 1\n",
    "    \n",
    "    print(f\"Loaded a total of {len(all_graphs)} graphs.\")\n",
    "\n",
    "    # --- 2. Prepare and Prune Features ---\n",
    "    # For pruning, represent each graph's node features by their mean\n",
    "    node_features_for_pruning = []\n",
    "    if all_node_features and all_node_features[0]:\n",
    "        feature_keys = all_node_features[0][0].keys() # \n",
    "        for graph_node_features in all_node_features:\n",
    "            if graph_node_features:\n",
    "                mean_features = {key: np.mean([nf[key] for nf in graph_node_features]) for key in feature_keys} # \n",
    "            else: # Handle graphs with no nodes # \n",
    "                mean_features = {key: 0.0 for key in feature_keys} # \n",
    "            node_features_for_pruning.append(mean_features)\n",
    "\n",
    "    print(\"\\n--- Starting Node-Level Feature Pruning ---\")\n",
    "    pruned_node_features_means, num_node_features = prune_features(node_features_for_pruning, all_labels, level='node') # \n",
    "    \n",
    "    print(\"\\n--- Starting Graph-Level Feature Pruning ---\")\n",
    "    pruned_graph_features, num_graph_features = prune_features(all_graph_features, all_labels, level='graph') # \n",
    "\n",
    "    important_node_feature_names = list(pruned_node_features_means[0].keys()) if pruned_node_features_means else []\n",
    "    print(f\"\\nRetained {num_node_features} node features: {important_node_feature_names}\")\n",
    "    print(f\"Retained {num_graph_features} graph features: {list(pruned_graph_features[0].keys()) if pruned_graph_features else []}\")\n",
    "\n",
    "    # --- 3. Convert to PyG Dataset ---\n",
    "    pyg_data = convert_to_pyg(all_graphs, all_node_features, important_node_feature_names, pruned_graph_features, all_labels)\n",
    "    \n",
    "    # --- 4. Save Processed Data ---\n",
    "    with open(DATA_PKL_PATH, 'wb') as f:\n",
    "        pickle.dump(pyg_data, f)\n",
    "    print(f\"\\nPreprocessing complete. Saved {len(pyg_data)} PyG data objects to {DATA_PKL_PATH}.\")\n",
    "\n",
    "    return pyg_data, num_node_features, num_graph_features\n",
    "\n",
    "\n",
    "def prepare_dataloaders(pyg_data):\n",
    "    \"\"\"\n",
    "    Splits PyG data into training and testing sets and creates DataLoaders.\n",
    "\n",
    "    Args:\n",
    "        pyg_data (list): A list of PyG `Data` objects.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing (train_loader, test_loader).\n",
    "    \"\"\"\n",
    "    num_train = int(len(pyg_data) * TRAIN_RATIO)\n",
    "    train_data = pyg_data[:num_train]\n",
    "    test_data = pyg_data[num_train:]\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE_TRAIN, shuffle=True) # \n",
    "    test_loader = DataLoader(test_data, batch_size=BATCH_SIZE_TRAIN, shuffle=False) # \n",
    "    \n",
    "    print(f\"Data split into {len(train_data)} training and {len(test_data)} testing samples.\")\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0384b6-a7ba-4a42-9d72-6d82257e1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GNN MODEL DEFINITIONS\n",
    "\"\"\"\n",
    "\n",
    "class GraphFamilyClassifierBase(nn.Module):\n",
    "    \"\"\"\n",
    "    A base class for Graph Neural Network classifiers.\n",
    "\n",
    "    This class defines the common architecture, including batch normalization,\n",
    "    dropout, and fully connected layers. Child classes must implement the\n",
    "    `define_conv_layer_1` and `define_conv_layer_2` methods to specify the\n",
    "    GNN convolution layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes, graph_feature_dim, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.conv1 = self.define_conv_layer_1(in_channels, hidden_channels)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_channels) # \n",
    "        self.conv2 = self.define_conv_layer_2(hidden_channels, hidden_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_channels) # \n",
    "        \n",
    "        # FC layers combine GNN output with graph-level features\n",
    "        self.fc1 = nn.Linear(hidden_channels + graph_feature_dim, hidden_channels)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_channels) # \n",
    "        self.fc2 = nn.Linear(hidden_channels, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def define_conv_layer_1(self, in_channels, hidden_channels):\n",
    "        \"\"\"Must be overridden by child class to define the first conv layer.\"\"\"\n",
    "        raise NotImplementedError # \n",
    "\n",
    "    def define_conv_layer_2(self, hidden_channels, out_channels):\n",
    "        \"\"\"Must be overridden by child class to define the second conv layer.\"\"\"\n",
    "        raise NotImplementedError # \n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Defines the forward pass for the classifier.\n",
    "\n",
    "        Args:\n",
    "            data (torch_geometric.data.Batch): A batch of graph data.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing (logits, embeddings).\n",
    "        \"\"\"\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # GNN layers\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.bn1(x) # \n",
    "        x = self.dropout(x) # \n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.bn2(x) # \n",
    "        x = self.dropout(x) # \n",
    "\n",
    "        # Global pooling and feature concatenation\n",
    "        x = global_mean_pool(x, batch)\n",
    "        graph_features = data.graph_features.view(x.shape[0], -1)\n",
    "        x = torch.cat([x, graph_features], dim=1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn3(x) # \n",
    "        embeddings = self.dropout(x) # \n",
    "        logits = self.fc2(embeddings)\n",
    "\n",
    "        return logits, embeddings\n",
    "\n",
    "\n",
    "class GraphFamilyClassifierGCN(GraphFamilyClassifierBase):\n",
    "    \"\"\"GCN-based classifier.\"\"\"\n",
    "    def define_conv_layer_1(self, in_channels, hidden_channels):\n",
    "        return GCNConv(in_channels, hidden_channels)\n",
    "    def define_conv_layer_2(self, hidden_channels, out_channels):\n",
    "        return GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "class GraphFamilyClassifierGAT(GraphFamilyClassifierBase):\n",
    "    \"\"\"GAT-based classifier.\"\"\"\n",
    "    def define_conv_layer_1(self, in_channels, hidden_channels):\n",
    "        return GATConv(in_channels, hidden_channels, heads=1, concat=True) # \n",
    "    def define_conv_layer_2(self, hidden_channels, out_channels):\n",
    "        return GATConv(hidden_channels, out_channels, heads=1, concat=False)\n",
    "\n",
    "class GraphFamilyClassifierGATV2(GraphFamilyClassifierBase):\n",
    "    \"\"\"GATv2-based classifier.\"\"\"\n",
    "    def define_conv_layer_1(self, in_channels, hidden_channels):\n",
    "        return GATv2Conv(in_channels, hidden_channels, heads=1, concat=True) # \n",
    "    def define_conv_layer_2(self, hidden_channels, out_channels):\n",
    "        return GATv2Conv(hidden_channels, out_channels, heads=1, concat=False)\n",
    "\n",
    "class GraphFamilyClassifierSAGE(GraphFamilyClassifierBase):\n",
    "    \"\"\"GraphSAGE-based classifier.\"\"\"\n",
    "    def define_conv_layer_1(self, in_channels, hidden_channels):\n",
    "        return SAGEConv(in_channels, hidden_channels) # \n",
    "    def define_conv_layer_2(self, hidden_channels, out_channels):\n",
    "        return SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "class GraphFamilyClassifierGIN(GraphFamilyClassifierBase):\n",
    "    \"\"\"GIN-based classifier.\"\"\"\n",
    "    def _make_mlp(self, in_dim, out_dim):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_dim, out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_dim, out_dim) # \n",
    "        )\n",
    "    def define_conv_layer_1(self, in_channels, hidden_channels):\n",
    "        mlp = self._make_mlp(in_channels, hidden_channels)\n",
    "        return GINConv(mlp, train_eps=True)\n",
    "    def define_conv_layer_2(self, hidden_channels, out_channels):\n",
    "        mlp = self._make_mlp(hidden_channels, out_channels)\n",
    "        return GINConv(mlp, train_eps=True)\n",
    "\n",
    "class GraphFamilyClassifierGTN(GraphFamilyClassifierBase):\n",
    "    \"\"\"Graph Transformer-based classifier.\"\"\"\n",
    "    def define_conv_layer_1(self, in_channels, hidden_channels):\n",
    "        return TransformerConv(in_channels, hidden_channels, heads=1, concat=True)\n",
    "    def define_conv_layer_2(self, hidden_channels, out_channels):\n",
    "        return TransformerConv(hidden_channels, out_channels, heads=1, concat=False)\n",
    "\n",
    "\n",
    "def get_model_from_arch(model_name, num_node_features, num_graph_features, hidden_channels, dropout_rate):\n",
    "    \"\"\"Factory function to instantiate a model by name.\"\"\"\n",
    "    num_classes = len(FAMILIES)\n",
    "    model_map = {\n",
    "        'GCN': GraphFamilyClassifierGCN,\n",
    "        'GAT': GraphFamilyClassifierGAT,\n",
    "        'GATV2': GraphFamilyClassifierGATV2, # \n",
    "        'SAGE': GraphFamilyClassifierSAGE,\n",
    "        'GIN': GraphFamilyClassifierGIN,\n",
    "        'GTN': GraphFamilyClassifierGTN, # \n",
    "    }\n",
    "    model_class = model_map.get(model_name)\n",
    "    if model_class:\n",
    "        return model_class(num_node_features, hidden_channels, num_classes, num_graph_features, dropout_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_name}\") # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa581a0d-7ca7-430d-8acb-be8fa96178ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HYPERPARAMETER TUNING (OPTUNA)\n",
    "\"\"\"\n",
    "\n",
    "def objective(trial, model_name, num_node_features, num_graph_features, train_loader, test_loader):\n",
    "    \"\"\"\n",
    "    Optuna objective function for hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    hidden_channels = trial.suggest_categorical(\"hidden_channels\", [32, 64, 96, 128])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 3e-3, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.2, 0.5)\n",
    "\n",
    "    try:\n",
    "        model = get_model_from_arch(model_name, num_node_features, num_graph_features, hidden_channels, dropout_rate).to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Training and validation loop for the trial\n",
    "        start = time.time()\n",
    "        for epoch in range(10): \n",
    "            model.train()\n",
    "            for data in train_loader:\n",
    "                data = data.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                out, _ = model(data)\n",
    "                loss = criterion(out, data.y)\n",
    "                \n",
    "                if torch.isnan(loss):\n",
    "                    print(f\"Trial {trial.number} pruned due to NaN loss at epoch {epoch}.\")\n",
    "                    raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "                loss.backward()\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "\n",
    "            val_loss, val_acc = evaluate_one_epoch(model, test_loader, criterion, DEVICE)\n",
    "            \n",
    "            if np.isnan(val_loss):\n",
    "                 print(f\"Trial {trial.number} pruned due to NaN validation loss.\")\n",
    "                 raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "            scheduler.step(val_loss)\n",
    "            trial.report(val_loss, epoch)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "        end = time.time()\n",
    "        \n",
    "        trial.set_user_attr(\"val_accuracy\", val_acc)\n",
    "        trial.set_user_attr(\"model_name\", model_name)\n",
    "        trial.set_user_attr(\"num_params\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "        trial.set_user_attr(\"training_time\", end-start)\n",
    "\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        if 'out of memory' in str(e).lower():\n",
    "            print(f\"Trial {trial.number} ran out of memory and was pruned.\")\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "\n",
    "def run_hyperparameter_tuning(num_node_features, num_graph_features, train_loader, test_loader):\n",
    "    \"\"\"\n",
    "    Performs hyperparameter tuning for all GNN models using Optuna.\n",
    "\n",
    "    Args:\n",
    "        num_node_features (int): Number of node features.\n",
    "        num_graph_features (int): Number of graph features.\n",
    "        train_loader (DataLoader): The training data loader.\n",
    "        test_loader (DataLoader): The testing data loader.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame summarizing the best trial for each architecture.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Hyperparameter Tuning ---\")\n",
    "    best_trials = []\n",
    "    for model_name in MODELS:\n",
    "        print(f\"\\nTuning {model_name}...\")\n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), # \n",
    "            sampler=optuna.samplers.TPESampler(seed=SEED) # \n",
    "        )\n",
    "        study.optimize(\n",
    "            lambda trial: objective(trial, model_name, num_node_features, num_graph_features, train_loader, test_loader),\n",
    "            n_trials=NUM_TRIALS_OPTUNA,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        best_trials.append(study.best_trial)\n",
    "\n",
    "    # Compile and save results\n",
    "    trial_data = []\n",
    "    for trial in best_trials:\n",
    "        data = {\n",
    "            'Architecture': trial.user_attrs['model_name'],\n",
    "            'Validation Loss': trial.value,\n",
    "            'Validation Accuracy': trial.user_attrs['val_accuracy'],\n",
    "            'Hidden Channels': trial.params['hidden_channels'],\n",
    "            'Learning Rate': trial.params['learning_rate'],\n",
    "            'Dropout Rate': trial.params['dropout_rate'],\n",
    "            'Training Time': trial.user_attrs['training_time'],\n",
    "            'Model Size': trial.user_attrs['num_params'],\n",
    "        }\n",
    "        trial_data.append(data)\n",
    "    \n",
    "    best_trials_df = pd.DataFrame(trial_data).sort_values(by='Validation Loss').reset_index(drop=True)\n",
    "    best_trials_df.to_csv('best_trials_summary.csv', index=False)\n",
    "    print(\"\\nHyperparameter tuning complete. Best trials summary:\")\n",
    "    display(best_trials_df)\n",
    "    return best_trials_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1b48b5-a945-4f8d-b800-5ad13ad9cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MODEL TRAINING AND EVALUATION\n",
    "\"\"\"\n",
    "\n",
    "def evaluate_one_epoch(model, loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to evaluate. \n",
    "        loader (DataLoader): The data loader for evaluation.\n",
    "        criterion: The loss function.\n",
    "        device: The device to run on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing (average_loss, accuracy). \n",
    "    \"\"\"\n",
    "    model.eval() # \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out, _ = model(data) # \n",
    "            loss = criterion(out, data.y)\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred == data.y).sum().item()\n",
    "            total += data.y.size(0) # \n",
    "    \n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "def final_training_loop(model, arch, optimizer, scheduler, criterion, train_loader, val_loader, device):\n",
    "    \"\"\"\n",
    "    Trains a model with early stopping and saves the best version.\n",
    "\n",
    "    Args:\n",
    "        model, arch, optimizer, scheduler, criterion: Standard training components.\n",
    "        train_loader, val_loader: Data loaders.\n",
    "        device: The device to run on.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing training history and checkpoint path.\n",
    "    \"\"\"\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    epochs_no_improve = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    save_path = os.path.join(FINAL_MODELS_DIR, f\"{arch}_best.pt\")\n",
    "\n",
    "    for epoch in range(1, MAX_EPOCHS_TRAIN + 1): # \n",
    "        # --- Training Step ---\n",
    "        model.train()\n",
    "        total_train_loss, correct_train, total_train = 0, 0, 0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(batch)\n",
    "            loss = criterion(logits, batch.y) # \n",
    "            loss.backward() # \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * batch.num_graphs\n",
    "            total_train += batch.num_graphs # \n",
    "            correct_train += (logits.argmax(dim=1) == batch.y).sum().item()\n",
    "\n",
    "        history['train_loss'].append(total_train_loss / total_train)\n",
    "        history['train_acc'].append(correct_train / total_train)\n",
    "\n",
    "        # --- Validation Step ---\n",
    "        val_loss, val_acc = evaluate_one_epoch(model, val_loader, criterion, device)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc) # \n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | Train Loss: {history['train_loss'][-1]:.4f} | \" # \n",
    "              f\"Train Acc: {history['train_acc'][-1]:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\") # \n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # --- Early Stopping and Model Checkpointing ---\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"  -> New best model saved to {save_path}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1 # \n",
    "\n",
    "        if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}. Best epoch was {best_epoch}.\")\n",
    "            break\n",
    "\n",
    "    return {**history, \"best_epoch\": best_epoch, \"best_val_loss\": best_val_loss, \"checkpoint\": save_path} # \n",
    "\n",
    "\n",
    "def run_final_training(best_trials_df, num_node_features, num_graph_features, train_loader, test_loader):\n",
    "    \"\"\"\n",
    "    Trains the best version of each model architecture found during tuning.\n",
    "\n",
    "    Args:\n",
    "        best_trials_df (pd.DataFrame): DataFrame with best hyperparameters.\n",
    "        num_node_features, num_graph_features: Feature dimensions.\n",
    "        train_loader, test_loader: Data loaders.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Final Model Training ---\")\n",
    "    metrics_dict = {'Architecture': [], 'Metrics': []}\n",
    "\n",
    "    for _, row in best_trials_df.iterrows():\n",
    "        arch = row['Architecture']\n",
    "        params = row.to_dict()\n",
    "        print(f\"\\nTraining best {arch} model with params: {params}\")\n",
    "\n",
    "        model = get_model_from_arch(\n",
    "            model_name=arch,\n",
    "            num_node_features=num_node_features,\n",
    "            num_graph_features=num_graph_features,\n",
    "            hidden_channels=params['Hidden Channels'],\n",
    "            dropout_rate=params['Dropout Rate']\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=params['Learning Rate'])\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "\n",
    "        results = final_training_loop(model, arch, optimizer, scheduler, criterion, train_loader, test_loader, DEVICE) # \n",
    "        \n",
    "        metrics_dict['Architecture'].append(arch)\n",
    "        metrics_dict['Metrics'].append(results) # \n",
    "        \n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    with open(METRICS_PKL_PATH, 'wb') as f:\n",
    "        pickle.dump(metrics_dict, f)\n",
    "    print(f\"\\nFinal training complete. Metrics saved to {METRICS_PKL_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1520e4-75d6-49cb-b06c-8ff3819b37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RESULTS - VISUALISATION & ANALYSIS\n",
    "\"\"\"\n",
    "\n",
    "def visualise_embeddings(model, name, dataloader, device):\n",
    "    \"\"\"\n",
    "    Generates and saves 2D t-SNE and 3D UMAP visualizations of graph embeddings.\n",
    "\n",
    "    Args:\n",
    "        model: A trained model capable of outputting embeddings.\n",
    "        name (str): The name of the model for titles and filenames.\n",
    "        dataloader: The data loader to generate embeddings from.\n",
    "        device: The device to run on.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    embeddings, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            data = data.to(device)\n",
    "            _, emb = model(data)\n",
    "            embeddings.append(emb.cpu().numpy())\n",
    "            labels.append(data.y.cpu().numpy())\n",
    "\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    labels = np.hstack(labels)\n",
    "    label_names = [FAMILY_NAMES_PRETTY[l] for l in labels]\n",
    "\n",
    "    # --- 2D t-SNE plot ---\n",
    "    tsne = TSNE(n_components=2, perplexity=min(30, len(embeddings) - 1), random_state=SEED)\n",
    "    tsne_result = tsne.fit_transform(embeddings)\n",
    "    df_tsne = pd.DataFrame({\"x\": tsne_result[:, 0], \"y\": tsne_result[:, 1], \"label\": label_names})\n",
    "\n",
    "    plt.figure(figsize=(12, 9)) \n",
    "    sns.scatterplot(data=df_tsne, x=\"x\", y=\"y\", hue=\"label\", hue_order=FAMILY_NAMES_PRETTY, palette=CLASS_COLORS, alpha=0.9, s=70) \n",
    "    plt.title(f\"t-SNE Embedding Visualization ({name})\", fontsize=26) \n",
    "    plt.xlabel(\"x\", fontsize=24) \n",
    "    plt.ylabel(\"y\", fontsize=24) \n",
    "    plt.legend(title=\"Graph Family\", loc='upper left', bbox_to_anchor=(1.05, 1), fontsize=28, title_fontsize=28, markerscale=2) \n",
    "    plt.subplots_adjust(right=0.85)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOT_DIR, f\"{name}_tsne.pdf\"),bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # --- 3D UMAP plot ---\n",
    "    reducer = umap.UMAP(n_neighbors=20, min_dist=0.5, n_components=3, random_state=SEED, spread=2.5)\n",
    "    umap_result = reducer.fit_transform(embeddings)\n",
    "    label_colors = [CLASS_COLORS[label] for label in label_names]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 10)) \n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    scatter = ax.scatter(umap_result[:, 0], umap_result[:, 1], umap_result[:, 2], c=label_colors, alpha=0.9, s=50) \n",
    "    ax.set_title(f\"3D UMAP Embedding Visualization ({name})\", fontsize=26) \n",
    "    ax.set_xlabel(\"UMAP 1\", fontsize=14) \n",
    "    ax.set_ylabel(\"UMAP 2\", fontsize=14) \n",
    "    ax.set_zlabel(\"UMAP 3\", fontsize=14) \n",
    "\n",
    "    ax.set_xlim(umap_result[:, 0].min(), umap_result[:, 0].max())\n",
    "    ax.set_ylim(umap_result[:, 1].min(), umap_result[:, 1].max())\n",
    "    ax.set_zlim(umap_result[:, 2].min(), umap_result[:, 2].max())\n",
    "    \n",
    "    # Proportional 3D box\n",
    "    ax.set_box_aspect([np.ptp(umap_result[:, 0]),np.ptp(umap_result[:, 1]),np.ptp(umap_result[:, 2])])\n",
    "    \n",
    "    # Create custom legend with increased font sizes\n",
    "    handles = [plt.Line2D([], [], marker='o', color='w', label=label, markerfacecolor=CLASS_COLORS[label], markersize=25) for label in FAMILY_NAMES_PRETTY] # Increased marker size in legend\n",
    "    ax.legend(\n",
    "        handles=handles,\n",
    "        title=\"Graph Family\",\n",
    "        loc='upper left',             \n",
    "        bbox_to_anchor=(1.05, 1),        \n",
    "        fontsize=28,\n",
    "        title_fontsize=28,\n",
    "        borderaxespad=0.\n",
    "    )\n",
    "    plt.subplots_adjust(right=0.85)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOT_DIR, f\"{name}_umap.pdf\"),bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def comprehensive_evaluation(model, name, loader, device, metrics_entry):\n",
    "    \"\"\"\n",
    "    Performs a full evaluation of a model and generates all relevant plots and reports.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model.\n",
    "        name (str): The model's architecture name.\n",
    "        loader: The test data loader.\n",
    "        device: The device to run on.\n",
    "        metrics_entry (dict): Dictionary with training history (loss/acc).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    y_true, y_pred, y_prob = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            logits, _ = model(batch)\n",
    "            probs = F.softmax(logits, dim=1).cpu().numpy()\n",
    "            y_true.extend(batch.y.cpu().numpy())\n",
    "            y_pred.extend(probs.argmax(axis=1))\n",
    "            y_prob.extend(probs)\n",
    "\n",
    "    y_true, y_pred, y_prob = np.array(y_true), np.array(y_pred), np.array(y_prob)\n",
    "\n",
    "    print(f\"\\n--- Comprehensive Evaluation for {name} ---\")\n",
    "\n",
    "    # 1. Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='pred')\n",
    "    plt.figure(figsize=(8, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"coolwarm\", xticklabels=FAMILY_NAMES_PRETTY, yticklabels=FAMILY_NAMES_PRETTY, annot_kws={\"size\":26})\n",
    "    plt.xlabel(\"Predicted Label\"), plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"Confusion Matrix ({name})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOT_DIR, f\"{name}_confusion_matrix.pdf\"))\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Classification Report\n",
    "    report = classification_report(y_true, y_pred, target_names=FAMILY_NAMES_PRETTY, digits=4, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_df.to_csv(f\"{name}_classification_report.csv\")\n",
    "    print(\"Classification Report:\")\n",
    "    display(report_df)\n",
    "\n",
    "    # 3. ROC and Precision-Recall Curves\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    for i, class_name in enumerate(FAMILY_NAMES_PRETTY):\n",
    "        # ROC\n",
    "        fpr, tpr, _ = roc_curve(y_true == i, y_prob[:, i])\n",
    "        auc = roc_auc_score(y_true == i, y_prob[:, i])\n",
    "        ax1.plot(fpr, tpr, label=f\"{class_name} (AUC={auc:.3f})\")\n",
    "        # Precision-Recall\n",
    "        precision, recall, _ = precision_recall_curve(y_true == i, y_prob[:, i])\n",
    "        ap = average_precision_score(y_true == i, y_prob[:, i])\n",
    "        ax2.plot(recall, precision, label=f\"{class_name} (AP={ap:.3f})\")\n",
    "\n",
    "    ax1.plot([0, 1], [0, 1], 'k--')\n",
    "    ax1.set_xlabel(\"False Positive Rate\"), ax1.set_ylabel(\"True Positive Rate\")\n",
    "    ax1.set_title(f\"ROC Curve ({name})\"), ax1.legend()\n",
    "    ax2.set_xlabel(\"Recall\"), ax2.set_ylabel(\"Precision\")\n",
    "    ax2.set_title(f\"Precision-Recall Curve ({name})\"), ax2.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOT_DIR, f\"{name}_roc_pr_curves.pdf\"))\n",
    "    plt.show()\n",
    "\n",
    "    # 4. Training History Plots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    ax1.plot(metrics_entry['train_loss'], label=\"Train Loss\")\n",
    "    ax1.plot(metrics_entry['val_loss'], label=\"Validation Loss\")\n",
    "    ax1.set_title(f\"Loss per Epoch ({name})\"), ax1.set_xlabel(\"Epoch\"), ax1.set_ylabel(\"Loss\"), ax1.legend()\n",
    "    ax2.plot(metrics_entry['train_acc'], label=\"Train Accuracy\")\n",
    "    ax2.plot(metrics_entry['val_acc'], label=\"Validation Accuracy\")\n",
    "    ax2.set_title(f\"Accuracy per Epoch ({name})\"), ax2.set_xlabel(\"Epoch\"), ax2.set_ylabel(\"Accuracy\"), ax2.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOT_DIR, f\"{name}_training_history.pdf\"))\n",
    "    plt.show()\n",
    "\n",
    "    # 5. Embedding Visualization\n",
    "    print(\"Generating embedding visualizations...\")\n",
    "    visualise_embeddings(model, name, loader, device)\n",
    "\n",
    "\n",
    "def run_svm_baseline(pyg_data):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a baseline SVM classifier on the graph features.\n",
    "\n",
    "    Args:\n",
    "        pyg_data (list): The PyG dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Running SVM Baseline ---\")\n",
    "    \n",
    "    # Prepare data for SVM\n",
    "    X, y = [], []\n",
    "    for data in pyg_data:\n",
    "        #  Aggregate node features (mean) and combine with graph features\n",
    "        node_feats = torch.mean(data.x, dim=0).cpu().numpy() if data.x.numel() > 0 else np.zeros(data.x.shape[-1] if data.x.numel() > 0 else 0)\n",
    "        graph_feats = data.graph_features.cpu().numpy() if data.graph_features.numel() > 0 else np.array([])\n",
    "        combined = np.concatenate([node_feats, graph_feats])\n",
    "        X.append(combined)\n",
    "        y.append(data.y.item()) # \n",
    "    X, y = np.vstack(X), np.array(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1-TRAIN_RATIO), stratify=y, random_state=SEED)\n",
    "\n",
    "    svm = SVC(kernel=\"rbf\", C=1.0, random_state=SEED, probability=True)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred) # \n",
    "    print(f\"SVM Accuracy: {acc:.4f}\") # \n",
    "\n",
    "    report = classification_report(y_test, y_pred, target_names=FAMILY_NAMES_PRETTY, digits=4, output_dict=True) # \n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_df.to_csv(\"SVM_classification_report.csv\")\n",
    "    print(\"SVM Classification Report:\")\n",
    "    display(report_df)\n",
    "\n",
    "\n",
    "def run_full_evaluation():\n",
    "    \"\"\"\n",
    "    Loads all trained models and metrics to run comprehensive evaluations and comparisons.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"      RUNNING FULL MODEL EVALUATION AND ANALYSIS\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    # Load data\n",
    "    with open(DATA_PKL_PATH, 'rb') as f:\n",
    "        pyg_data = pickle.load(f)\n",
    "    with open(METRICS_PKL_PATH, 'rb') as f:\n",
    "        metrics_dict_data = pickle.load(f)\n",
    "    \n",
    "    _, test_loader = prepare_dataloaders(pyg_data)\n",
    "    best_trials_df = pd.read_csv('best_trials_summary.csv')\n",
    "    \n",
    "\n",
    "    arch_names = metrics_dict_data['Architecture']\n",
    "    metrics_list = metrics_dict_data['Metrics']\n",
    "    metrics_map = {arch: metrics for arch, metrics in zip(arch_names, metrics_list)}\n",
    " \n",
    "\n",
    "    # Evaluate each GNN model\n",
    "    for _, row in best_trials_df.iterrows(): # \n",
    "        arch = row['Architecture']\n",
    "        model_path = os.path.join(FINAL_MODELS_DIR, f\"{arch}_best.pt\")\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Skipping {arch}: Checkpoint not found at {model_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Instantiate model and load weights\n",
    "        num_node_features = test_loader.dataset[0].x.shape[1]\n",
    "        num_graph_features = test_loader.dataset[0].graph_features.shape[0]\n",
    "        model = get_model_from_arch(\n",
    "            model_name=arch,\n",
    "            num_node_features=num_node_features,\n",
    "            num_graph_features=num_graph_features,\n",
    "            hidden_channels=row['Hidden Channels'],\n",
    "            dropout_rate=row['Dropout Rate']\n",
    "        ).to(DEVICE)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "\n",
    "        comprehensive_evaluation(\n",
    "            model=model,\n",
    "            name=arch,\n",
    "            loader=test_loader,\n",
    "            device=DEVICE,\n",
    "            metrics_entry=metrics_map[arch]\n",
    "        )\n",
    "    \n",
    "    # Evaluate SVM baseline\n",
    "    run_svm_baseline(pyg_data)\n",
    "\n",
    "    # Aggregate and display final results\n",
    "    print(\"\\n\\n--- Final Performance Summary ---\")\n",
    "    csv_files = [f for f in os.listdir() if f.endswith('_classification_report.csv')]\n",
    "    \n",
    "    all_metrics = []\n",
    "    for file in csv_files:\n",
    "        arch = file.replace('_classification_report.csv', '')\n",
    "        df = pd.read_csv(file, index_col=0)\n",
    "        df.rename(columns={'precision': 'Precision', 'recall': 'Recall', 'f1-score': 'F1-Score', 'support': 'Support'}, inplace=True)\n",
    "        df['Architecture'] = arch\n",
    "        all_metrics.append(df)\n",
    "        \n",
    "    summary_df = pd.concat(all_metrics).reset_index().rename(columns={'index': 'Family'})\n",
    "    \n",
    "    for metric in ['Precision', 'Recall', 'F1-Score']:\n",
    "        metric_df = summary_df.pivot(index='Architecture', columns='Family', values=metric)\n",
    "        metric_df = metric_df.drop(columns=['accuracy', 'macro avg', 'weighted avg'], errors='ignore')\n",
    "        metric_df['Mean'] = metric_df.mean(axis=1)\n",
    "        metric_df = metric_df.sort_values(by='Mean', ascending=False)\n",
    "        print(f\"\\n{metric} Results:\")\n",
    "        display(metric_df)\n",
    "        metric_df.to_csv(f'final_{metric}_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f052890-5dbf-4dd8-a401-cafc356547eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MAIN EXECUTION\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Set up the environment\n",
    "setup_environment()\n",
    "\n",
    "# Step 2: Generate the graph data\n",
    "run_batched_generation()\n",
    "\n",
    "# Step 3: Preprocess the data and save it\n",
    "pyg_data, num_node_features, num_graph_features = load_and_preprocess_dataset()\n",
    "\n",
    "# Step 4: Prepare data loaders\n",
    "train_loader, test_loader = prepare_dataloaders(pyg_data)\n",
    "\n",
    "# Step 5: Tune hyperparameters\n",
    "best_trials_df = run_hyperparameter_tuning(num_node_features, num_graph_features, train_loader, test_loader)\n",
    "\n",
    "# Step 6: Train the final models using the best hyperparameters\n",
    "run_final_training(best_trials_df, num_node_features, num_graph_features, train_loader, test_loader)\n",
    "\n",
    "# Step 7: Run the final evaluation and generate all plots/reports\n",
    "run_full_evaluation()"
   ]
  },
 
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
